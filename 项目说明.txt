基于用户特征、基于内容特征、基于环境特征和基于网络特征
用户个人信息：用户名长度、用户简介长度、账号注册时间、用户名命名规则、
用户行为
好友关系：好友数、粉丝数、关注数/粉丝、二阶好友数
消息内容
整个项目流程：基于用户特征、基于内容特征、基于环境特征和基于网络特征
   1、通过预处理实验材料（复旦大学微博数据），赛选出潜在垃圾用户
   2、通过爬虫去现在的新浪微博，爬这些用户，提取那些现在不存在了的用户。
   3、现在不存在的这部分用户（可能是一些原因被封），提取这些用户的微博信息，分析特征，分类等采用数据挖掘的方法进行分析
   4、再检验调整，以期望识别微博水军及垃圾用户，具有比较好的效果。
   
   
   
   
  第一阶段：基于用户特征的 
 一、基于用户特征的分析
  本阶段的目的是采取各种预处理手段从大量的源文本数据中去除不大可能是水军的用户，换句话说，就是进一步精简得到潜在垃圾用户列表。
  1、过滤认证用户
  2、提取用户名，对用户名进行Ngram相似性分析，提取非常见用户名，保存为潜在垃圾用户列表（实践中是从用户名四个字以上的开始取得，取25万个进行再分析）
  3、提取上面用户名对应的UID，保存为UID列表。根据这个列表去weibo_follows.csv中提取每个用户的关注的UID，以及关注他的UID分别保存。
             然后提取那些既有关注别人又有别人关注的用户做进一步分的分析（有七万多个）。
  4、提取用户特征，表示出用的粉丝数，关注数，并对整个用户按关注别人数量的多少进行降序排列。
   
   *********************************
            进度说明
   *********************************
二、
1、根据标识过滤现有的微博用户，目的是过滤掉那些认证用户（认证用户是垃圾用户的可能性不大）
2、提取用户名，进行预处理，目的是过滤掉大多正常用户。方法是，对用户名进行Ngram相似的分析，社会学上来讲，一般来讲人的用户名大多具有一些意义，
       所以一些词可能是大家命名时都爱使用的，这些词组成的名字相对来讲是水军垃圾用户的可能性要比随机一些用户来讲低一些。所以这一步的目的就是，进行Ngram
       分析按出现概率降序排列用户名，然后取部分作为潜在垃圾用户，以对他们进行进一步的分析。（实验过程中，发现一些两个字的及三个字的用户名作为低频大量出现，
       原因是这些大多是真的人名，作为人名一般不是词语或者常见的，所以在整个用户名组成的空间中出现的概率就比较低，而对于我们的目的来讲，显然这部分人是水军 的
       可能性也比较低，所以对这部分还需要舍弃。现在的做法是，去除四个字一下的用户名，然后去低频的25万人的用户作为潜在垃圾用户列表保存）
3、从源文件提取关注关系，第一步得到的25W个用户uid,去源文件follows_users.csv提取他们的关注关系，包括他们关注别人的，以及别粉丝关注，两方面的
       关系，分别都表示出来。
       由于爬取的原因，实验发现在25W个用户在源关注关系中只有七万多个有关注别人，也只有七万多人有被别人关注。由于要进行再爬取，所以这里挑选那些既有关注别人
       也有别人关注的用户uid提取出来，保存为潜在垃圾用户列表。并且提取关系，把用户表示为他关注的用户的uid，以及把用户表示为他粉丝uid。
4、把用户表示为他关注的用户的uid的词向量，这里使用的是word2vec深度学习的词向量工具。（这一步可能后期才能用到，现在只是了解word2vec的直观使用）
4月18——4月20
5、对上面得到的七万多的用户中，提取三角关注关系，社会学上三角关系是一种稳定的关系，是水军的可能性不太大，前期处理可以通过这种操作过滤部分样本用户，进一步精确潜在垃圾用户列表。
6、统计用户的关注数，粉丝数，计算关注数、粉丝数，并根据关注数降序排列，保存为用户及属性列表。
7、对关注量做分析，如找出平均关注量，然后赛选那些过渡关注 的用户ID这部分用户是可能性更大。
8、提取出七万多个用户的profile信息，以进一步对他们进行分析。
4月21-4月28日
9、根据珍妮Ngram的结果（90万左右）重新做所有的过程，确保正确性。根据现在已经爬的7777个不存在uid，提取交集，得到提取特征uid。
10、提取不存在列表中的用户特征：基本是根据老师上次让做的，一些文件有的格式，先提取这些基础的特征。
     提取用户性别信息 格式：uid f/m
     提取fuid
     提取边
5月2-5月6日提取用户特征信息
5月7日-5月11日提取特征
设计，提取微博相似度的特征。
5月12-5月19日 
1、特征优化
2、重新提取正类样本，排序Ngram后的干扰
3、对比试验，对比不同特征对分类的作用，从而选取最优的子集特征空间 。
4、负类样本中海油许多本是正类的，而错误的分类成了水军，这种要去除掉，不然会很干扰分类准确率。
5、探索水军关系特征，这是创新的主要方向
5月22日-5月26日
1、微博相似度使用编辑距离也不合适，编辑距离只有对非常相似的字符串，才有效果，由于微博文本较长，所以应该做cos相似度
2、5月23日bczhang提出三个比较创新的特征点:分别是微博源特征（组合特征表示，使用词汇丰富度）、用户主动@的用户是否是他的朋友统计这个比例、根据用户朋友，提取出这个用户特征（
如IT类，新闻类，娱乐）关于这个现在一个简单的做法是分组统计关注每一类的个数
3、下面具体谈一下每一个怎么做。
微博源特征
 现在一个问题是，有的用户微博数非常的少比如只有一条或者几条，这种用户统计微博源数就不具有意义而且会造成误分类。
 这个解决办法是：组合特征的办法，比如微博数大于X作为一个特征为0 然后对这个用户进行微博源比例的分析，如果微博数小于X 就让特征作为一个定值比如1。老师还介绍了一个新的方法
 就是使用“词汇丰富度”，这个还没有具体搞明白。
 @朋友比例
 这个比较好处理，找到公平的做法就可以了。
 用户类别特征
 这个比较复杂，具体怎么做还要根据探索的结果进行分析。为简化具有可行性，由于大V是有类别属性的，所以可以根据用户的关注的大V的类别定义这个用户的类别。所以现在必要的就是，看看用户关注的
 用户中大Ｖ的比例什么样，有多少大V分布情况，以及如果需要就爬取这些大V的类别。
 
 